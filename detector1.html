<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>FFT e Rilevamento Note</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      text-align: center;
      padding: 20px;
    }
    canvas {
      border: 1px solid #ddd;
      margin: 20px auto;
      display: block;
    }
    .frequency, .note {
      font-size: 1.5em;
      margin-top: 20px;
    }
  </style>
</head>
<body>
  <h1>FFT e Rilevamento Note</h1>
  <button id="startButton">Avvia Microfono</button>
  <div class="frequency" id="frequency">Frequenza Dominante: -- Hz</div>
  <div class="note" id="note">Nota: --</div>

  <script>
    const startButton = document.getElementById('startButton');
    const frequencyDisplay = document.getElementById('frequency');
    const noteDisplay = document.getElementById('note');

    let audioContext, analyser, microphone, dataArray, sampleRate;

    // Tabella delle note e relative frequenze
    const noteFrequencies = [
  { note: "C2", freq: 65.41 },
  { note: "C#2", freq: 69.30 },
  { note: "D2", freq: 73.42 },
  { note: "D#2", freq: 77.78 },
  { note: "E2", freq: 82.41 },
  { note: "F2", freq: 87.31 },
  { note: "F#2", freq: 92.50 },
  { note: "G2", freq: 98.00 },
  { note: "G#2", freq: 103.83 },
  { note: "A2", freq: 110.00 },
  { note: "A#2", freq: 116.54 },
  { note: "B2", freq: 123.47 },

  { note: "C3", freq: 130.81 },
  { note: "C#3", freq: 138.59 },
  { note: "D3", freq: 146.83 },
  { note: "D#3", freq: 155.56 },
  { note: "E3", freq: 164.81 },
  { note: "F3", freq: 174.61 },
  { note: "F#3", freq: 185.00 },
  { note: "G3", freq: 196.00 },
  { note: "G#3", freq: 207.65 },
  { note: "A3", freq: 220.00 },
  { note: "A#3", freq: 233.08 },
  { note: "B3", freq: 246.94 },

  { note: "C4", freq: 261.63 },
  { note: "C#4", freq: 277.18 },
  { note: "D4", freq: 293.66 },
  { note: "D#4", freq: 311.13 },
  { note: "E4", freq: 329.63 },
  { note: "F4", freq: 349.23 },
  { note: "F#4", freq: 369.99 },
  { note: "G4", freq: 392.00 },
  { note: "G#4", freq: 415.30 },
  { note: "A4", freq: 440.00 },
  { note: "A#4", freq: 466.16 },
  { note: "B4", freq: 493.88 },

  { note: "C5", freq: 523.25 },
  { note: "C#5", freq: 554.37 },
  { note: "D5", freq: 587.33 },
  { note: "D#5", freq: 622.25 },
  { note: "E5", freq: 659.25 },
  { note: "F5", freq: 698.46 },
  { note: "F#5", freq: 739.99 },
  { note: "G5", freq: 783.99 },
  { note: "G#5", freq: 830.61 },
  { note: "A5", freq: 880.00 },
  { note: "A#5", freq: 932.33 },
  { note: "B5", freq: 987.77 },

  { note: "C6", freq: 1046.50 }
];

    async function startAudio() {
      try {
        // Create the audio context
        audioContext = new (window.AudioContext || window.webkitAudioContext)();

        //requests permission to access the user's microphone and obtains a stream of audio data, save it in variable stream.
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });

        /*Connect the microphone inputo to the audio context. 
        Allowing the audio stream of the microphone to be processed by the AudioContext. */
        microphone = audioContext.createMediaStreamSource(stream);

        // Initialize low-pass filter
        const lowpassFilter = audioContext.createBiquadFilter();
        lowpassFilter.type = 'lowpass'; // Low-pass filter to remove high-frequency noise
        lowpassFilter.frequency.value = 1000; // Cut-off frequency at 1000 Hz

        // Create and configure an analyser node
        analyser = audioContext.createAnalyser(); // Analyser node is now created to perform real-time frequency and time-domain analysis on the audio signal.
        /*Fast Fourier Transform size is set to 2048, which determines the resolution of the frequency analysis. 
        A larger size provides finer frequency detail but slower updates. */
        analyser.fftSize = 16384; // High resolution for frequency analysis
        analyser.minDecibels = -90; // Minimum decibel range
        //analyser.maxDecibels = -10; // Maximum decibel range for more precision

        // Chain the audio nodes: microphone -> low-pass filter -> analyser
        // Connects the MediaStreamSource (representing the audio stream from the microphone) to the AnalyserNode.
        // An AnalyserNode is an audio processing node that provides real-time analysis of audio data without modifying the audio signal.
        microphone.connect(analyser);
        microphone.connect(lowpassFilter);
        lowpassFilter.connect(analyser);


        /* Create a new 8-bit integer array (Uint8Array) called dataArray which size is determined by analyser.frequencyBinCount.
        The size is half the size of the fftSize. 
        Each element in dataArray will hold an amplitude value for a specific frequency range, scaled between 0 and 255.
        This array is where the frequency domain data (FFT output) from the AnalyserNode will be stored. It is used to process 
        or visualize the frequency spectrum of the audio signal.
        A bin refers to a range of frequencies represented in the output of the Fast Fourier Transform (FFT). 
        Each bin corresponds to a small slice of the entire frequency spectrum.*/
        dataArray = new Uint8Array(analyser.frequencyBinCount);

        /*Retrieves the sample rate of the AudioContext and assigns it to the variable sampleRate. Is the number of audio samples
        processed per second. OBS: frequency of bin n = (n * SampleRate / fftSize)  */
        sampleRate = audioContext.sampleRate;

        // Function updateFFT is called to start the process of continuously analyzing the frequency spectrum of the audio in real-time.
        updateFFT();

      } //error handling:
        catch (error) {
        alert('Errore durante l\'accesso al microfono: ' + error.message);
      }
    }


    function updateFFT() {
        /* Populate the dataArray with the frequency-domain data (amplitudes) from the AnalyserNode.
        Now dataArray contains values (0â€“255) representing the intensity of frequencies in the audio signal */
        analyser.getByteFrequencyData(dataArray);

        /* Find the frequency with the highest amplitude (dominant frequency) in the dataArray.
          Input:
          - dataArray: Contains the amplitude values for each frequency bin.
          - analyser.frequencyBinCount: Number of bins (frequency ranges) in the spectrum.
          - sampleRate: Sampling rate of the audio context.
        Output:
          - frequency (in Hz) that has the highest amplitude.
        */
        const dominantFrequency = getDominantFrequency(dataArray, analyser.frequencyBinCount, sampleRate, analyser.fftSize);

        const fundamentalFrequency = detectFundamentalFrequency(dominantFrequency, dataArray);

        // I am now trying without using teh detectFundamentalFrequency method
        //const fundamentalFrequency = dominantFrequency

        // Find the closest note
        const closestNote = getClosestNote(fundamentalFrequency);

        // Show the freq and the note
        frequencyDisplay.textContent = `Frequenza Dominante: ${fundamentalFrequency.toFixed(2)} Hz`;
        noteDisplay.textContent = `Nota: ${closestNote.note}`;

        // Update every ___ ms
        setTimeout(updateFFT, 400);
    }

    function getDominantFrequency(dataArray, binCount, sampleRate, fftSize) {
      let maxIndex = 0;         // keep track of the array index
      let maxValue = -Infinity; // stores the maximum amplitude value found during the loop.
      /* Loops through all frequency bins (binCount). Compares the amplitude of each bin and store the max value and index */
      for (let i = 0; i < binCount; i++) {
        if (dataArray[i] > maxValue) {
          maxValue = dataArray[i];
          maxIndex = i;
        }
      }

      /*
      // INTERPOLATION TO FIND A MORE ACCURATE FREQ:
      if (maxIndex > 0 && maxIndex < binCount - 1) {
        const left = dataArray[maxIndex - 1];
        const center = dataArray[maxIndex];
        const right = dataArray[maxIndex + 1];

        // Parabolic interpolation to estimate the peak frequency more accurately
        const interpolationFactor = (left - right) / (2 * (2 * center - left - right));
        maxIndex += interpolationFactor;
      } */

      return (maxIndex * sampleRate) / fftSize;
    }

    function detectFundamentalFrequency(dominantFreq, spectrum, sampleRate, fftSize) {
      if (dominantFreq <= 0) return dominantFreq; // Handle edge case where frequency is invalid

      const harmonicThreshold = 0.8;                      // Ratio threshold to consider a harmonic
      const searchHarmonics = 10;                         // Number of harmonics to analyze
      const minAmplitude = Math.max(...spectrum) * 0.1;   // Minimum amplitude threshold to consider as valid: 10% of the peak spectrum amplitude

      // Start by assuming the fundamental frequency is the dominant frequency
      let fundamentalFreq = dominantFreq;

      // Convert the spectrum to frequency-domain bins
      const spectrumBins = Array.from({ length: spectrum.length }, (_, i) => 
        (i * sampleRate) / fftSize
      );

      // Iterate over potential harmonics
      for (let harmonic = 1; harmonic <= searchHarmonics; harmonic++) {
        const candidateFreq = dominantFreq / harmonic;

        if (candidateFreq < 20) break; // Ignore unrealistic low frequencies

        // Find the nearest frequency bin to the candidate frequency
        const binIndex = spectrumBins.findIndex((freq) => Math.abs(freq - candidateFreq) < sampleRate / fftSize);

        if (binIndex > 0 && spectrum[binIndex] > minAmplitude) {
          const amplitudeRatio = spectrum[binIndex] / spectrum[Math.round((dominantFreq / (sampleRate / 2)) * spectrum.length)];

          if (amplitudeRatio > harmonicThreshold) {
            fundamentalFreq = candidateFreq; // Update the fundamental frequency
            break;
          }
        }
      }

      return fundamentalFreq;
    }

    function getClosestNote(freq) {
      if (freq <= 0) return { note: "--", freq: 0 };

      // As closest note take a generical note
      let closestNote = noteFrequencies[0];

      // Store diff between freq and notefreq
      let minDiff = Math.abs(freq - noteFrequencies[0].freq);

      // loop to find the note whose freq is the closest to the dominant frequency
      for (let i = 1; i < noteFrequencies.length; i++) {
        const diff = Math.abs(freq - noteFrequencies[i].freq);
        if (diff < minDiff && diff < (noteFrequencies[i].freq * 0.05))  {
          minDiff = diff;
          closestNote = noteFrequencies[i];
        }
      }

      return closestNote;
    }


    startButton.addEventListener('click', startAudio);
  </script>
</body>
</html>


